# PyTorch Cookbook

[TOC]

## ä¸€. Basic concept [alpha]

### 1. numpy array å’Œ Tensor(CPU & GPU)

~~~shell
>>> import torch
>>> import numpy as np
>>> a = np.ones(5)
>>> a
array([1., 1., 1., 1., 1.])
>>> b = torch.from_numpy(a)     # numpy array-> CPU Tensor
>>> b 
tensor([1., 1., 1., 1., 1.], dtype=torch.float64)
>>> y = y.cuda()     # CPU Tensor -> GPU Tensor
>>> y
tensor([1., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float64)
>>> y = y.cpu()  # GPU Tensor-> CPU Tensor
>>> y
tensor([1., 1., 1., 1., 1.], dtype=torch.float64)
>>> y = y.numpy()  # CPU Tensor -> numpy array
>>> y
array([1., 1., 1., 1., 1.])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
>>> y = torch.from_numpy(y)
>>> y.to(device) # è¿™é‡Œ x.to(device) ç­‰ä»·äº x.cuda()
tensor([1., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float64)
~~~

ç´¢å¼•ã€ view æ˜¯ä¸ä¼šå¼€è¾Ÿæ–°å†…å­˜çš„ï¼Œè€Œåƒ y = x + y è¿™æ ·çš„è¿ç®—æ˜¯ä¼šæ–°å¼€å†…å­˜çš„ï¼Œç„¶åå°† y æŒ‡å‘æ–°å†…å­˜ã€‚

### 2. Variable å’Œã€€Tensor (require_grad=True)

â€‹    Pytorch 0.4 ä¹‹å‰çš„æ¨¡å¼ä¸º:ã€€**Tensor æ²¡æœ‰æ¢¯åº¦è®¡ç®—ï¼ŒåŠ ä¸Šæ¢¯åº¦æ›´æ–°ç­‰æ“ä½œåå¯ä»¥å˜ä¸ºVariable**.  Pytorch0.4 å°† Tensor å’ŒVariable åˆå¹¶ã€‚é»˜è®¤ Tensor çš„ require_grad ä¸º falseï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ requires_grad æ¥ä¸ºå…¶æ·»åŠ æ¢¯åº¦æ›´æ–°æ“ä½œã€‚

~~~python
>>> y
tensor([1., 1., 1., 1., 1.], dtype=torch.float64)  
>>> y.requires_grad
False
>>> y.requires_grad = True
>>> y
tensor([1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)
~~~

### 3. detach å’Œã€€with torch.no_grad()

ä¸€ä¸ªæ¯”è¾ƒå¥½çš„ detachå’Œ torch.no_gradåŒºåˆ«çš„è§£é‡Š:

>**`detach()` detaches the output from the computationnal graph. So no gradient will be backproped along this variable.**
>
>**`torch.no_grad` says that no operation should build the graph.**
>
>**The difference is that one refers to only a given variable on which itâ€™s called. The other affects all operations taking place within the with statement.**

`detach()` å°†ä¸€ä¸ªå˜é‡ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä¹Ÿæ²¡æœ‰äº†ç›¸å…³çš„æ¢¯åº¦æ›´æ–°ã€‚`torch.no_grad()`åªæ˜¯è¯´æ˜è¯¥æ“ä½œæ²¡å¿…è¦å»ºå›¾ã€‚ä¸åŒä¹‹å¤„åœ¨äºï¼Œå‰è€…åªèƒ½æŒ‡å®šä¸€ä¸ªç»™å®šçš„å˜é‡ï¼Œåè€… åˆ™ä¼šå½±å“å½±å“åœ¨ with è¯­å¥ä¸­å‘ç”Ÿçš„æ‰€æœ‰æ“ä½œã€‚

### 4. model.eval()ã€€å’Œ torch.no_grad()

>**These two have different goals:**
>
>- `model.eval()` will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.
>
>- `torch.no_grad()` impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop (which you donâ€™t want in an eval script).

`model.eval()`å’Œ`torch.no_grad()`çš„åŒºåˆ«åœ¨äºï¼Œ`model.eval()`æ˜¯å°†ç½‘ç»œåˆ‡æ¢ä¸ºæµ‹è¯•çŠ¶æ€ï¼Œä¾‹å¦‚BNå’Œéšæœºå¤±æ´»ï¼ˆdropoutï¼‰åœ¨è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µä½¿ç”¨ä¸åŒçš„è®¡ç®—æ–¹æ³•ã€‚`torch.no_grad()`æ˜¯å…³é—­PyTorchå¼ é‡çš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ï¼Œä»¥å‡å°‘å­˜å‚¨ä½¿ç”¨å’ŒåŠ é€Ÿè®¡ç®—ï¼Œå¾—åˆ°çš„ç»“æœæ— æ³•è¿›è¡Œ`loss.backward()`

### 5. xx.data å’Œ xx.detach()

â€‹      åœ¨ 0.4.0 ç‰ˆæœ¬ä¹‹å‰,  .data çš„è¯­ä¹‰æ˜¯ è·å– Variable çš„ å†…éƒ¨ Tensor, åœ¨ 0.4.0 ç‰ˆæœ¬å°† Variable å’Œ Tensor merge ä¹‹å,  `.data` å’Œä¹‹å‰æœ‰ç±»ä¼¼çš„è¯­ä¹‰ï¼Œ ä¹Ÿæ˜¯å†…éƒ¨çš„ Tensor çš„æ¦‚å¿µã€‚`x.data` ä¸ `x.detach()` è¿”å›çš„ tensor æœ‰ç›¸åŒçš„åœ°æ–¹, ä¹Ÿæœ‰ä¸åŒçš„åœ°æ–¹:

**ç›¸åŒ:**

- éƒ½å’Œ x å…±äº«åŒä¸€å—æ•°æ®
- éƒ½å’Œ x çš„ è®¡ç®—å†å²æ— å…³
- requires_grad = False

**ä¸åŒ:**

- y= x.data åœ¨æŸäº›æƒ…å†µä¸‹ä¸å®‰å…¨, æŸäº›æƒ…å†µ, æŒ‡çš„å°±æ˜¯ä¸Šè¿° inplace operation çš„ç¬¬äºŒç§æƒ…å†µ, æ‰€ä»¥, release note ä¸­æŒ‡å‡º, å¦‚æœæƒ³è¦ detach çš„æ•ˆæœçš„è¯, è¿˜æ˜¯ detach() å®‰å…¨ä¸€äº›.

~~~python
>>> import torch
>>> x = torch.FloatTensor([[1., 2.]])
>>> w1 = torch.FloatTensor([[2.], [1.]])
>>> w2 = torch.FloatTensor([3.])
>>> w1.requires_grad = True
>>> w2.requires_grad = True
>>> d = torch.matmul(x, w1)
>>> d_ = d.data
>>> f = torch.matmul(d, w2)
>>> d_[:] = 1
>>> f.backward()
~~~

**å¦‚æœéœ€è¦è·å–å…¶å€¼ï¼Œå¯ä»¥ä½¿ç”¨  xx.cpu().numpy() æˆ–è€… xx.cpu().detach().numpy() ç„¶åè¿›è¡Œæ“ä½œï¼Œä¸å»ºè®®å†ä½¿ç”¨ volatileå’Œ  xx.dataæ“ä½œã€‚**

### 6. ToTensor & ToPILImage å„è‡ªéƒ½åšäº†ä»€ä¹ˆ?

**ToTensor:**

- å–å€¼èŒƒå›´ï¼š   [0, 255]  -->  [0, 1.0]
- NHWC  --> NCHW
- PILImage  --> FloatTensor

~~~python
# PIL.Image -> torch.Tensor.
tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))
    ).permute(2, 0, 1).float() / 255
#ã€€ç­‰ä»·äº
tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) 
~~~

**ToPILImage:**

- å–å€¼èŒƒå›´:  [0, 1.0] -->  [0, 255]
- NCHW --> NHWC
- ç±»å‹: FloatTensor -> numpy Uint8 -> PILImage

~~~python
# torch.Tensor -> PIL.Image.
image = PIL.Image.fromarray(torch.clamp(tensor * 255, min=0, max=255
    ).byte().permute(1, 2, 0).cpu().numpy())
#ã€€ç­‰ä»·äº
image = torchvision.transforms.functional.to_pil_image(tensor) 
~~~

### 7. torch.nn.xxx ä¸ torch.nn.functional.xxx

å»ºè®®ç»Ÿä¸€ä½¿ç”¨ã€€`torch.nn.xxx`ã€€æ¨¡å—ï¼Œ`torch.functional.xxx` å¯èƒ½ä¼šåœ¨ä¸‹ä¸€ä¸ªç‰ˆæœ¬ä¸­å»æ‰ã€‚

`torch.nn`ã€€æ¨¡å—å’Œã€€`torch.nn.functional`ã€€çš„åŒºåˆ«åœ¨äºï¼Œ`torch.nn`ã€€æ¨¡å—åœ¨è®¡ç®—æ—¶åº•å±‚è°ƒç”¨äº†`torch.nn.functional`ï¼Œä½†ã€€`torch.nn`ã€€æ¨¡å—åŒ…æ‹¬è¯¥å±‚å‚æ•°ï¼Œè¿˜å¯ä»¥åº”å¯¹è®­ç»ƒå’Œæµ‹è¯•ä¸¤ç§ç½‘ç»œçŠ¶æ€ã€‚ä½¿ç”¨ã€€`torch.nn.functional`ã€€æ—¶è¦æ³¨æ„ç½‘ç»œçŠ¶æ€ï¼Œå¦‚:

~~~python
def forward(self, x):
    ...
    x = torch.nn.functional.dropout(x, p=0.5, training=self.training)
~~~



## äºŒ. Pytorch API [alpha]

### 1. import torch

import & vision

~~~python
import torch 
print(torch.__version__)
~~~

### 2. Tensor type ğŸŒŸ

Pytorch ç»™å‡ºäº† 9 ç§ CPU Tensor ç±»å‹å’Œ 9 ç§ GPU Tensor ç±»å‹ã€‚Pytorch ä¸­é»˜è®¤çš„æ•°æ®ç±»å‹æ˜¯ torch.FloatTensor, å³ torch.Tensor ç­‰åŒäº torch.FloatTensorã€‚

| Data type                | dtype                         | CPU tensor         | GPU tensor              |
| ------------------------ | ----------------------------- | ------------------ | ----------------------- |
| 32-bit floating point    | torch.float32 or torch.float  | torch.FloatTensor  | torch.cuda.FloatTensor  |
| 64-bit floating point    | torch.float64 or torch.double | torch.DoubleTensor | torch.cuda.DoubleTensor |
| 16-bit floating point    | torch.float16 or torch.half   | torch.HalfTensor   | torch.cuda.HalfTensor   |
| 8-bit integer (unsigned) | torch.uint8                   | torch.ByteTensor   | torch.cuda.ByteTensor   |
| 8-bit integer (signed)   | torch.int8                    | torch.CharTensor   | torch.cuda.CharTensor   |
| 16-bit integer (signed)  | torch.int16 or torch.short    | torch.ShortTensor  | torch.cuda.ShortTensor  |
| 32-bit integer (signed)  | torch.int32 or torch.int      | torch.IntTensor    | torch.cuda.IntTensor    |
| 64-bit integer (signed)  | torch.int64 or torch.long     | torch.LongTensor   | torch.cuda.LongTensor   |
| Boolean                  | torch.bool                    | torch.BoolTensor   | torch.cuda.BoolTensor   |

##### è®¾ç½®é»˜è®¤Tensor ç±»å‹

Pytorch å¯ä»¥é€šè¿‡ `set_default_tensor_type` å‡½æ•°**è®¾ç½®é»˜è®¤ä½¿ç”¨çš„Tensorç±»å‹**ï¼Œ åœ¨å±€éƒ¨ä½¿ç”¨å®Œåå¦‚æœéœ€è¦å…¶ä»–ç±»å‹ï¼Œåˆ™è¿˜éœ€è¦é‡æ–°è®¾ç½®ä¼šæ‰€éœ€çš„ç±»å‹ 

~~~
torch.set_default_tensor_type('torch.DoubleTensor')
~~~

##### CPU/GPU äº’è½¬

CPU Tensor å’Œ GPU Tensor çš„åŒºåˆ«åœ¨äºï¼Œ å‰è€…å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè€Œåè€…å­˜å‚¨åœ¨æ˜¾å­˜ä¸­ã€‚ä¸¤è€…ä¹‹é—´çš„è½¬æ¢å¯ä»¥é€šè¿‡ `.cpu()`ã€`.cuda()`å’Œ `.to(device)` æ¥å®Œæˆ  â€»

~~~python
>>> device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")  
>>> a = torch.rand(2,3)
>>> a = a.cuda() # CPU -> GPU
>>> a.type()
'torch.cuda.FloatTensor'
>>> a = a.cpu() # GPU -> CPU
>>> a.type()
'torch.FloatTensor'
>>> a = a.to(device) # CPU <->  GPU
>>> a.type()
'torch.cuda.FloatTensor'
~~~

##### åˆ¤å®š Tensor ç±»å‹çš„å‡ ç§æ–¹å¼: â€»

~~~python
>>> a
tensor([[0.6065, 0.0122, 0.4473],
        [0.5937, 0.5530, 0.4663]], device='cuda:0')
>>> a.is_cuda  # å¯ä»¥æ˜¾ç¤ºæ˜¯å¦åœ¨æ˜¾å­˜ä¸­
True
>>> a.dtype  # Tensor å†…éƒ¨dataçš„ç±»å‹
torch.float32
>>> a.type()
'torch.cuda.FloatTensor'  # å¯ä»¥ç›´æ¥æ˜¾ç¤ºTensorç±»å‹ = is_cuda + dtype
~~~

##### ç±»å‹è½¬æ¢

~~~python
>>> a
tensor([[0.6065, 0.0122, 0.4473],
        [0.5937, 0.5530, 0.4663]], device='cuda:0')
>>> a.type(torch.DoubleTensor)   # ä½¿ç”¨ type() å‡½æ•°è¿›è¡Œè½¬æ¢
tensor([[0.6065, 0.0122, 0.4473],
        [0.5937, 0.5530, 0.4663]], dtype=torch.float64)
>>> a = a.double()  # ç›´æ¥ä½¿ç”¨ int()ã€long() ã€float() ã€å’Œ double() ç­‰ç›´æ¥è¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢è¿›è¡Œ
tensor([[0.6065, 0.0122, 0.4473],
        [0.5937, 0.5530, 0.4663]], device='cuda:0', dtype=torch.float64)
>>> b = torch.randn(4,5)
>>> b.type_as(a)  # ä½¿ç”¨ type_as å‡½æ•°å¹¶ä¸éœ€è¦æ˜ç¡®å…·ä½“æ˜¯å“ªç§ç±»å‹
tensor([[ 0.2129,  0.1877, -0.0626,  0.4607, -1.0375],
        [ 0.7222, -0.3502,  0.1288,  0.6786,  0.5062],
        [-0.4956, -0.0793,  0.7590, -1.0932, -0.1084],
        [-2.2198,  0.3827,  0.2735,  0.5642,  0.6771]], device='cuda:0',
       dtype=torch.float64)
~~~

##### numpy array ä¸ã€€torch Tensorã€€äº’è½¬

~~~python
torch.Tensorä¸np.ndarrayè½¬æ¢
# torch.Tensor -> np.ndarray.
ndarray = tensor.cpu().numpy()

# np.ndarray -> torch.Tensor.
tensor = torch.from_numpy(ndarray).float()
tensor = torch.from_numpy(ndarray.copy()).float()  # If ndarray has negative stride
~~~

##### Tensor ç›¸å…³ä¿¡æ¯è·å–

~~~python
torch.size()/torch.shape   # ä¸¤è€…ç­‰ä»·ï¼Œ è¿”å›tçš„å½¢çŠ¶, å¯ä»¥ä½¿ç”¨ x.size()[1] æˆ– x.size(1) æŸ¥çœ‹åˆ—æ•°
torch.numel() / torch.nelement()  # ä¸¤è€…ç­‰ä»·, tä¸­å…ƒç´ æ€»ä¸ªæ•°
a.item()  # å–å‡ºå•ä¸ªtensorçš„å€¼
tensor.dim()  # ç»´åº¦
~~~

### 3. Tensor Create

##### æœ€åŸºæœ¬çš„Tensoråˆ›å»ºæ–¹å¼

~~~python
troch.Tensor(2, 2) # ä¼šä½¿ç”¨é»˜è®¤çš„ç±»å‹åˆ›å»º Tensor, å¯ä»¥é€šè¿‡ torch.set_default_tensor_type('torch.DoubleTensor') è¿›è¡Œä¿®æ”¹
torch.DoubleTensor(2, 2) # æŒ‡å®šç±»å‹åˆ›å»º Tensor

torch.Tensor([[1, 2], [3, 4]])  # é€šè¿‡ list åˆ›å»º Tensor          å°† Tensorè½¬æ¢ä¸ºlistå¯ä»¥ä½¿ç”¨: t.tolist():
torch.from_numpy(np.array([2, 3.3]) ) # é€šè¿‡ numpy array åˆ›å»º tensor
~~~

##### ç¡®å®šåˆå§‹å€¼çš„æ–¹å¼åˆ›å»º

~~~python
torch.ones(sizes)  # å…¨ 1 Tensor     
torch.zeros(sizes)  # å…¨ 0 Tensor
torch.eye(sizes)  # å¯¹è§’çº¿ä¸º1ï¼Œä¸è¦æ±‚è¡Œåˆ—ä¸€è‡´
torch.full(sizes, value) # æŒ‡å®š value
~~~

##### åˆ†å¸ƒ

~~~python
torch.rand(sizes)  # å‡åŒ€åˆ†å¸ƒ   
torch.randn(sizes)   # æ ‡å‡†åˆ†å¸ƒ
# æ­£æ€åˆ†å¸ƒ: è¿”å›ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«ä»ç»™å®šå‚æ•° means,std çš„ç¦»æ•£æ­£æ€åˆ†å¸ƒä¸­æŠ½å–éšæœºæ•°ã€‚ å‡å€¼ meansæ˜¯ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«æ¯ä¸ªè¾“å‡ºå…ƒç´ ç›¸å…³çš„æ­£æ€åˆ†å¸ƒçš„å‡å€¼ -> ä»¥æ­¤å¼ é‡çš„å‡å€¼ä½œä¸ºå‡å€¼
# stdæ˜¯ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«æ¯ä¸ªè¾“å‡ºå…ƒç´ ç›¸å…³çš„æ­£æ€åˆ†å¸ƒçš„æ ‡å‡†å·® -> ä»¥æ­¤å¼ é‡çš„æ ‡å‡†å·®ä½œä¸ºæ ‡å‡†å·®ã€‚ å‡å€¼å’Œæ ‡å‡†å·®çš„å½¢çŠ¶ä¸é¡»åŒ¹é…ï¼Œä½†æ¯ä¸ªå¼ é‡çš„å…ƒç´ ä¸ªæ•°é¡»ç›¸åŒ
torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))
tensor([-0.1987,  3.1957,  3.5459,  2.8150,  5.5398,  5.6116,  7.5512,  7.8650,
         9.3151, 10.1827])
torch.uniform(from,to) # å‡åŒ€åˆ†å¸ƒ 

torch.arange(s, e, steps)  # ä»såˆ°eï¼Œæ­¥é•¿ä¸ºstep
torch.linspace(s, e, num)   # ä»såˆ°e,å‡åŒ€åˆ‡åˆ†ä¸º num ä»½, æ³¨æ„linespaceå’Œarangeçš„åŒºåˆ«ï¼Œå‰è€…çš„æœ€åä¸€ä¸ªå‚æ•°æ˜¯ç”Ÿæˆçš„Tensorä¸­å…ƒç´ çš„æ•°é‡ï¼Œè€Œåè€…çš„æœ€åä¸€ä¸ªå‚æ•°æ˜¯æ­¥é•¿ã€‚
torch.randperm(m) # 0 åˆ° m-1 çš„éšæœºåºåˆ—
# --> shuffle æ“ä½œ
tensor[torch.randperm(tensor.size(0))] 
~~~

##### å¤åˆ¶

Pytorch æœ‰å‡ ç§ä¸åŒçš„å¤åˆ¶æ–¹å¼ï¼Œæ³¨æ„åŒºåˆ†

| Operation             | New/Shared memory | Still in computation graph |
| --------------------- | ----------------- | -------------------------- |
| tensor.clone()        | New               | Yes                        |
| tensor.detach()       | Shared            | No                         |
| tensor.detach.clone() | New               | No                         |

### 4. ç´¢å¼•ã€æ¯”è¾ƒã€æ’åº

##### ç´¢å¼•æ“ä½œ

~~~python
a.item() #ã€€ä»åªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ä¸­æå–å€¼

a[row, column]   # row è¡Œï¼Œ cloumn åˆ—
a[index]   # ç¬¬index è¡Œ
a[:,index]   # ç¬¬ index åˆ—

a[0, -1]  # ç¬¬é›¶è¡Œï¼Œ æœ€åä¸€ä¸ªå…ƒç´ 
a[:index]  # å‰ index è¡Œ
a[:row, 0:1]  # å‰ row è¡Œï¼Œ 0å’Œ1åˆ—

a[a>1]  # é€‰æ‹© a > 1çš„å…ƒç´ ï¼Œ ç­‰ä»·äº a.masked_select(a>1)
torch.nonzero(a) # é€‰æ‹©éé›¶å…ƒç´ çš„åæ ‡ï¼Œå¹¶è¿”å›
a.clamp(x, y)  # å¯¹ Tensor å…ƒç´ è¿›è¡Œé™åˆ¶ï¼Œ å°äºxç”¨xä»£æ›¿ï¼Œ å¤§äºyç”¨yä»£æ›¿
torch.where(condition, x, y)  # æ»¡è¶³condition çš„ä½ç½®è¾“å‡ºxï¼Œ å¦åˆ™è¾“å‡ºy
>>> a
tensor([[ 6., -2.],
        [ 8.,  0.]])
>>> torch.where(a > 1, torch.full_like(a, 1), a)  # å¤§äº1 çš„éƒ¨åˆ†ç›´æ¥ç”¨1ä»£æ›¿ï¼Œ å…¶ä»–ä¿ç•™åŸå€¼
tensor([[ 1., -2.],
        [ 1.,  0.]])

#ã€€å¾—åˆ°éé›¶å…ƒç´ 
torch.nonzero(tensor)               # éé›¶å…ƒç´ çš„ç´¢å¼•
torch.nonzero(tensor == 0)          # é›¶å…ƒç´ çš„ç´¢å¼•
torch.nonzero(tensor).size(0)       # éé›¶å…ƒç´ çš„ä¸ªæ•°
torch.nonzero(tensor == 0).size(0)  # é›¶å…ƒç´ çš„ä¸ªæ•°
~~~

##### æ¯”è¾ƒæ“ä½œ

~~~python
gt >    lt <     ge >=     le <=   eq ==    ne != 
topk(input, k) -> (Tensor, LongTensor)
sort(input) -> (Tensor, LongTensor)
max/min => max(tensor)      max(tensor, dim)    max(tensor1, tensor2)
~~~

sort å‡½æ•°æ¥å—ä¸¤ä¸ªå‚æ•°, å…¶ä¸­ å‚æ•° 0 ä¸ºæŒ‰ç…§è¡Œæ’åºã€1ä¸ºæŒ‰ç…§åˆ—æ’åº: True ä¸ºé™åºï¼Œ False ä¸ºå‡åºï¼Œ è¿”å›å€¼æœ‰ä¸¤ä¸ªï¼Œ ç¬¬ä¸€ä¸ªæ˜¯æ’åºç»“æœï¼Œ ç¬¬äºŒä¸ªæ˜¯æ’åºåºå·

~~~python
>>> import torch
>>> a = torch.randn(3, 3)
>>> a
tensor([[-1.8500, -0.2005,  1.4475],
        [-1.7795, -0.4968, -1.8965],
        [ 0.5798, -0.1554,  1.6395]])
>>> a.sort(0, True)[0] 
tensor([[ 0.5798, -0.1554,  1.6395],
        [-1.7795, -0.2005,  1.4475],
        [-1.8500, -0.4968, -1.8965]])
>>> a.sort(0, True)[1]
tensor([[2, 2, 2],
        [1, 0, 0],
        [0, 1, 1]])
>>> a.sort(1, True)[1]
tensor([[2, 1, 0],
        [1, 0, 2],
        [2, 0, 1]])
>>> a.sort(1, True)[0]
tensor([[ 1.4475, -0.2005, -1.8500],
        [-0.4968, -1.7795, -1.8965],
        [ 1.6395,  0.5798, -0.1554]])
~~~

### 5. Element-wise å’Œ å½’å¹¶æ“ä½œ

Element-wiseï¼šè¾“å‡ºçš„ Tensor å½¢çŠ¶ä¸åŸå§‹çš„å½¢çŠ¶ä¸€è‡´

~~~python
abs / sqrt / div / exp / fmod / log / pow...
cos / sin / asin / atan2 / cosh...
ceil / round / floor / trunc
clamp(input, min, max)
sigmoid / tanh...
~~~

å½’å¹¶æ“ä½œï¼šè¾“å‡ºçš„ Tensor å½¢çŠ¶å°äºåŸå§‹çš„ Tensorå½¢çŠ¶

~~~python
mean/sum/median/mode   # å‡å€¼/å’Œ/ ä¸­ä½æ•°/ä¼—æ•°
norm/dist  # èŒƒæ•°/è·ç¦»
std/var  # æ ‡å‡†å·®/æ–¹å·®
cumsum/cumprd # ç´¯åŠ /ç´¯ä¹˜
~~~

### 6. å˜å½¢æ“ä½œ

##### view/resize/reshape  è°ƒæ•´Tensorçš„å½¢çŠ¶

- å…ƒç´ æ€»æ•°å¿…é¡»ç›¸åŒ  
- view å’Œ reshape å¯ä»¥ä½¿ç”¨ -1 è‡ªåŠ¨è®¡ç®—ç»´åº¦
- å…±äº«å†…å­˜

!!!  `view()` æ“ä½œæ˜¯éœ€è¦ Tensor åœ¨å†…å­˜ä¸­è¿ç»­çš„ï¼Œ è¿™ç§æƒ…å†µä¸‹éœ€è¦ä½¿ç”¨ `contiguous()` æ“ä½œå…ˆå°†å†…å­˜å˜ä¸ºè¿ç»­ã€‚ å¯¹äºreshape æ“ä½œï¼Œ å¯ä»¥çœ‹åšæ˜¯ `Tensor.contiguous().view()`.

~~~python
>>> a = torch.Tensor(2,2)
>>> a
tensor([[6.0000e+00, 8.0000e+00],
        [1.0000e+00, 1.8367e-40]])
>>> a.resize(4, 1)
tensor([[6.0000e+00],
        [8.0000e+00],
        [1.0000e+00],
        [1.8367e-40]])
~~~

##### transpose / permute  å„ç»´åº¦ä¹‹é—´çš„å˜æ¢ï¼Œ 

transpose å¯ä»¥å°†æŒ‡å®šçš„ä¸¤ä¸ªç»´åº¦çš„å…ƒç´ è¿›è¡Œè½¬ç½®ï¼Œ permute åˆ™å¯ä»¥æŒ‰ç…§æŒ‡å®šçš„ç»´åº¦è¿›è¡Œç»´åº¦å˜æ¢

~~~python
>>> x
tensor([[[-0.9699, -0.3375, -0.0178]],
        [[ 1.4260, -0.2305, -0.2883]]])

>>> x.shape
torch.Size([2, 1, 3])
>>> x.transpose(0, 1) # shape => torch.Size([1, 2, 3])
tensor([[[-0.9699, -0.3375, -0.0178],
         [ 1.4260, -0.2305, -0.2883]]])
>>> x.permute(1, 0, 2) # shape => torch.Size([1, 2, 3])
tensor([[[-0.9699, -0.3375, -0.0178],
         [ 1.4260, -0.2305, -0.2883]]])
>>> 
~~~

##### squeeze(dim) / unsquence(dim)  

å¤„ç†sizeä¸º1çš„ç»´åº¦ï¼Œ å‰è€…ç”¨äºå»é™¤sizeä¸º1çš„ç»´åº¦ï¼Œ è€Œåè€…åˆ™æ˜¯å°†æŒ‡å®šçš„ç»´åº¦çš„sizeå˜ä¸º1

~~~python
>>> a = torch.arange(1, 4)
>>> a
tensor([1, 2, 3]) # shape => torch.Size([3])
>>> a.unsqueeze(0) # shape => torch.Size([1, 3])
>>> a.unqueeze(0).squeeze(0) # shape => torch.Size([3])
~~~

##### expand / expand_as / repeatå¤åˆ¶å…ƒç´ æ¥æ‰©å±•ç»´åº¦

æœ‰æ—¶éœ€è¦é‡‡ç”¨å¤åˆ¶çš„å½¢å¼æ¥æ‰©å±• Tensor çš„ç»´åº¦ï¼Œ è¿™æ—¶å¯ä»¥ä½¿ç”¨ `expand`ï¼Œ `expand()` å‡½æ•°å°† size ä¸º 1çš„ç»´åº¦å¤åˆ¶æ‰©å±•ä¸ºæŒ‡å®šå¤§å°ï¼Œ ä¹Ÿå¯ä»¥ç”¨ `expand_as() `å‡½æ•°æŒ‡å®šä¸º ç¤ºä¾‹ Tensor çš„ç»´åº¦ã€‚

!! `expand` æ‰©å¤§ tensor ä¸éœ€è¦åˆ†é…æ–°å†…å­˜ï¼Œåªæ˜¯ä»…ä»…æ–°å»ºä¸€ä¸ª tensor çš„è§†å›¾ï¼Œå…¶ä¸­é€šè¿‡å°† stride è®¾ä¸º0ï¼Œä¸€ç»´å°†ä¼šæ‰©å±•ä½æ›´é«˜ç»´ã€‚

`repeat` æ²¿ç€æŒ‡å®šçš„ç»´åº¦é‡å¤ tensorã€‚ ä¸åŒäº `expand()`ï¼Œå¤åˆ¶çš„æ˜¯ tensor ä¸­çš„æ•°æ®ã€‚

~~~python
>>> a = torch.rand(2, 2, 1)
>>> a
tensor([[[0.3094],
         [0.4812]],

        [[0.0950],
         [0.8652]]])
>>> a.expand(2, 2, 3) # å°†ç¬¬2ç»´çš„ç»´åº¦ç”±1å˜ä¸º3ï¼Œ åˆ™å¤åˆ¶è¯¥ç»´çš„å…ƒç´ ï¼Œå¹¶æ‰©å±•ä¸º3
tensor([[[0.3094, 0.3094, 0.3094],
         [0.4812, 0.4812, 0.4812]],

        [[0.0950, 0.0950, 0.0950],
         [0.8652, 0.8652, 0.8652]]])

>>> a.repeat(1, 2, 1) # å°†ç¬¬äºŒä½å¤åˆ¶ä¸€æ¬¡
tensor([[[0.3094],
         [0.4812],
         [0.3094],
         [0.4812]],

        [[0.0950],
         [0.8652],
         [0.0950],
         [0.8652]]])
~~~

##### ä½¿ç”¨åˆ‡ç‰‡æ“ä½œæ‰©å±•å¤šä¸ªç»´åº¦

~~~
b = a[:,None, None,:] # None å¤„çš„ç»´åº¦ä¸ºï¼‘
~~~

### 7. ç»„åˆä¸åˆ†å—

**ç»„åˆæ“ä½œ** æ˜¯å°†ä¸åŒçš„ Tensor å åŠ èµ·æ¥ã€‚ ä¸»è¦æœ‰ `cat()` å’Œ `torch.stack()` ä¸¤ä¸ªå‡½æ•°ï¼Œcat å³ concatenate çš„æ„æ€ï¼Œ æ˜¯æŒ‡æ²¿ç€å·²æœ‰çš„æ•°æ®çš„æŸä¸€ç»´åº¦è¿›è¡Œæ‹¼æ¥ï¼Œ æ“ä½œåçš„æ•°æ®çš„æ€»ç»´æ•°ä¸å˜ï¼Œ åœ¨è¿›è¡Œæ‹¼æ¥æ—¶ï¼Œ é™¤äº†æ‹¼æ¥çš„ç»´åº¦ä¹‹å¤–ï¼Œ å…¶ä»–ç»´åº¦å¿…é¡»ç›¸åŒã€‚ è€Œ` torch. stack()` å‡½æ•°ä¼šæ–°å¢ä¸€ä¸ªç»´åº¦ï¼Œ å¹¶æŒ‰ç…§æŒ‡å®šçš„ç»´åº¦è¿›è¡Œå åŠ ã€‚

~~~shell
torch.cat(list_of_tensors, dim=0)ã€€  # kä¸ª(m,n) -> (k*m, n)
torch.stack(list_of_tensors, dim=0)   # kä¸ª(m,n) -> (k*m*n)
~~~

**åˆ†å—æ“ä½œ** æ˜¯æŒ‡å°† Tensor åˆ†å‰²æˆä¸åŒçš„å­ Tensorï¼Œä¸»è¦æœ‰ `torch.chunk()` ä¸ `torch.split()` ä¸¤ä¸ªå‡½æ•°ï¼Œå‰è€…éœ€è¦æŒ‡å®šåˆ†å—çš„æ•°é‡ï¼Œè€Œåè€…åˆ™éœ€è¦æŒ‡å®šæ¯ä¸€å—çš„å¤§å°ï¼Œä»¥æ•´å½¢æˆ–è€…listæ¥è¡¨ç¤ºã€‚

~~~python
>>> a = torch.Tensor([[1,2,3], [4,5,6]])
>>> torch.chunk(a, 2, 0)
(tensor([[1., 2., 3.]]), tensor([[4., 5., 6.]]))
>>> torch.chunk(a, 2, 1)
(tensor([[1., 2.],
        [4., 5.]]), tensor([[3.],
        [6.]]))
>>> torch.split(a, 2, 0)
(tensor([[1., 2., 3.],
        [4., 5., 6.]]),)
>>> torch.split(a, [1, 2], 1)
(tensor([[1.],
        [4.]]), tensor([[2., 3.],
        [5., 6.]]))
~~~

### 8. linear algebra

~~~python
trace  # å¯¹è§’çº¿å…ƒç´ ä¹‹å’Œ(çŸ©é˜µçš„è¿¹)
diag  # å¯¹è§’çº¿å…ƒç´ 
triu/tril  # çŸ©é˜µçš„ä¸Šä¸‰è§’/ä¸‹ä¸‰è§’
addmm/addbmm/addmv/addr/badbmm...  # çŸ©é˜µè¿ç®—
t # è½¬ç½®
dor/cross # å†…ç§¯/å¤–ç§¯
inverse # çŸ©é˜µæ±‚é€†
svd  # å¥‡å¼‚å€¼åˆ†è§£

torch.mm(tensor1, tensor2)   # çŸ©é˜µä¹˜æ³•  (m*n) * (n*p) -> (m*p)
torch.bmm(tensor1, tensor2) # batchçš„çŸ©é˜µä¹˜æ³•: (b*m*n) * (b*n*p) -> (b*m*p).
torch.mv(tensor, vec) #ã€€çŸ©é˜µå‘é‡ä¹˜æ³• (m*n) * (n) = (m)
tensor1 * tensor2 # Element-wise multiplication.
~~~

### 9. åŸºæœ¬æœºåˆ¶

##### å¹¿æ’­æœºåˆ¶

ä¸åŒå½¢çŠ¶çš„ Tensor è¿›è¡Œè®¡ç®—æ—¶ï¼Œ å¯ä»¥è‡ªåŠ¨æ‰©å±•åˆ°è¾ƒå¤§çš„ç›¸åŒå½¢çŠ¶å†è¿›è¡Œè®¡ç®—ã€‚ å¹¿æ’­æœºåˆ¶çš„å‰ææ˜¯ä¸€ä¸ª Tensor  è‡³å°‘æœ‰ä¸€ä¸ªç»´åº¦ï¼Œä¸”ä»å°¾éƒ¨éå† Tensor æ—¶ï¼Œä¸¤è€…ç»´åº¦å¿…é¡»ç›¸ç­‰ï¼Œ å…¶ä¸­ä¸ƒä¸ªè¦ä¹ˆæ˜¯1ï¼Œ è¦ä¹ˆä¸å­˜åœ¨

##### å‘é‡åŒ–æ“ä½œ

å¯ä»¥åœ¨åŒä¸€æ—¶é—´è¿›è¡Œæ‰¹é‡åœ°å¹¶è¡Œè®¡ç®—ï¼Œä¾‹å¦‚çŸ©é˜µè¿ç®—ï¼Œä»¥è¾¾åˆ°æ›´é«˜çš„è®¡ç®—æ•ˆç‡çš„ä¸€ç§æ–¹å¼:

##### å…±äº«å†…å­˜æœºåˆ¶

(1) ç›´æ¥é€šè¿‡ Tensor æ¥åˆå§‹åŒ–å¦ä¸€ä¸ª Tensorï¼Œ æˆ–è€…é€šè¿‡ Tensor çš„ç»„åˆã€åˆ†å—ã€ç´¢å¼•ã€å˜å½¢æ¥åˆå§‹åŒ–å¦ä¸€ä¸ªTensorï¼Œ åˆ™è¿™ä¸¤ä¸ª Tensor å…±äº«å†…å­˜:

~~~python
>>> a = torch.randn(2,3)
>>> b = a
>>> c = a.view(6)
>>> b[0, 0] = 0
>>> c[3] = 4
>>> a
tensor([[ 0.0000,  0.3898, -0.7641],
        [ 4.0000,  0.6859, -1.5179]])
~~~

(2) å¯¹äºä¸€äº›æ“ä½œé€šè¿‡åŠ åç¼€  â€œ\_â€  å®ç° inplace æ“ä½œï¼Œ å¦‚ `add_()` å’Œ `resize_()` ç­‰ï¼Œ è¿™æ ·æ“ä½œåªè¦è¢«æ‰§è¡Œï¼Œ æœ¬èº«çš„ Tensor å°±ä¼šè¢«æ”¹å˜ã€‚

~~~
>>> a
tensor([[ 0.0000,  0.3898, -0.7641],
        [ 4.0000,  0.6859, -1.5179]])
>>> a.add_(a)
tensor([[ 0.0000,  0.7796, -1.5283],
        [ 8.0000,  1.3719, -3.0358]])
~~~

(3) Tensorä¸ Numpy å¯ä»¥é«˜æ•ˆçš„å®Œæˆè½¬æ¢ï¼Œ å¹¶ä¸”è½¬æ¢å‰åçš„å˜é‡å…±äº«å†…å­˜ã€‚åœ¨è¿›è¡Œ Pytorch ä¸æ”¯æŒçš„æ“ä½œçš„æ—¶å€™ï¼Œ ç”šè‡³å¯ä»¥æ›²çº¿æ•‘å›½ï¼Œ å°† Tensor è½¬æ¢ä¸º Numpy ç±»å‹ï¼Œæ“ä½œåå†è½¬åŒ–ä¸º Tensor

~~~
# tensor <--> numpy
b = a.numpy() # tensor -> numpy
a = torch.from_numpy(a) # numpy -> tensor
~~~

!!! éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`torch.tensor()` æ€»æ˜¯ä¼šè¿›è¡Œæ•°æ®æ‹·è´ï¼Œæ–° tensor å’ŒåŸæ¥çš„æ•°æ®ä¸å†å…±äº«å†…å­˜ã€‚æ‰€ä»¥å¦‚æœä½ æƒ³å…±äº«å†…å­˜çš„è¯ï¼Œå»ºè®®ä½¿ç”¨ `torch.from_numpy()` æˆ–è€… `tensor.detach()` æ¥æ–°å»ºä¸€ä¸ª tensor, äºŒè€…å…±äº«å†…å­˜ã€‚

### 10. nn

~~~python
from torch import nn
import torch.nn.functional as F
~~~

##### pad å¡«å……

~~~python
nn.ConstantPad2d(padding, value)
~~~

##### å·ç§¯å’Œåå·ç§¯

~~~python
nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)
~~~

~~~python
#ã€€æœ€å¸¸ç”¨çš„ä¸¤ç§å·ç§¯å±‚è®¾è®¡ 3x3 & 1x1
conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)
conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True)
~~~

##### æ± åŒ–å±‚

~~~python
nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)
nn.AdaptiveMaxPool2d(output_size, return_indices=False)
nn.AdaptiveAvgPool2d(output_size)  # global avg pool: output_size=1
nn.MaxUnpool2d(kernel_size, stride=None, padding=0)
~~~

##### å…¨è¿æ¥å±‚

~~~python
nn.Linear(in_features, out_features, bias=True)
~~~

##### é˜²æ­¢è¿‡æ‹Ÿåˆç›¸å…³å±‚

~~~python
nn.Dropout2d(p=0.5, inplace=False)
nn.AlphaDropout(p=0.5)
nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
~~~

##### æ¿€æ´»å‡½æ•°

~~~python
nn.Softplus(beta=1, threshold=20)
nn.Tanh()
nn.ReLU(inplace=False)    
nn.ReLU6(inplace=False)
nn.LeakyReLU(negative_slope=0.01, inplace=False)
nn.PReLU(num_parameters=1, init=0.25)
nn.SELU(inplace=False)
nn.ELU(alpha=1.0, inplace=False)
~~~

##### RNN 

~~~python
nn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh')
nn.RNN(*args, **kwargs)
nn.LSTMCell(input_size, hidden_size, bias=True)
nn.LSTM(*args, **kwargs)
nn.GRUCell(input_size, hidden_size, bias=True)
nn.GRU(*args, **kwargs)
~~~

##### Embedding

~~~python
nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False, _weight=None)
~~~

##### Sequential

~~~python
nn.Sequential(*args)
~~~

##### loss functon

~~~python
nn.BCELoss(weight=None, size_average=True, reduce=True)
nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100, reduce=True)
# CrossEntropyLoss ç­‰ä»·äº log_softmax + NLLLoss
nn.L1Loss(size_average=True, reduce=True)
nn.KLDivLoss(size_average=True, reduce=True)
nn.MSELoss(size_average=True, reduce=True)
nn.NLLLoss(weight=None, size_average=True, ignore_index=-100, reduce=True)
nn.NLLLoss2d(weight=None, size_average=True, ignore_index=-100, reduce=True)
nn.SmoothL1Loss(size_average=True, reduce=True)
nn.SoftMarginLoss(size_average=True, reduce=True)
nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-06, swap=False, size_average=True, reduce=True)
nn.CosineEmbeddingLoss(margin=0, size_average=True, reduce=True)
~~~

##### functional

~~~python
nn.functional # nnä¸­çš„å¤§å¤šæ•°layerï¼Œåœ¨functionalä¸­éƒ½æœ‰ä¸€ä¸ªä¸ä¹‹ç›¸å¯¹åº”çš„å‡½æ•°ã€‚
              # nn.functionalä¸­çš„å‡½æ•°å’Œnn.Moduleçš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œ
              # ç”¨nn.Moduleå®ç°çš„layersæ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ç±»ï¼Œéƒ½æ˜¯ç”± class layer(nn.Module)å®šä¹‰ï¼Œ
              # ä¼šè‡ªåŠ¨æå–å¯å­¦ä¹ çš„å‚æ•°ã€‚è€Œnn.functionalä¸­çš„å‡½æ•°æ›´åƒæ˜¯çº¯å‡½æ•°ï¼Œ
              # ç”±def function(input)å®šä¹‰ã€‚
~~~

##### init

~~~python
torch.nn.init.uniform
torch.nn.init.normal
torch.nn.init.kaiming_uniform
torch.nn.init.kaiming_normal
torch.nn.init.xavier_normal
torch.nn.init.xavier_uniform
torch.nn.init.sparse
~~~

##### net

~~~python
class net_name(nn.Module):
    def __init__(self):
        super(net_name, self).__init__()
        self.layer_name = xxxx

    def forward(self, x): 
        x = self.layer_name(x)        
        return x

net.parameters()   # è·å–å‚æ•° 
net.named_parameters  # è·å–å‚æ•°åŠåç§°
net.zero_grad()  # ç½‘ç»œæ‰€æœ‰æ¢¯åº¦æ¸…é›¶, grad åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ˜¯ç´¯åŠ çš„(accumulated)ï¼Œ
                 # è¿™æ„å‘³ç€æ¯ä¸€æ¬¡è¿è¡Œåå‘ä¼ æ’­ï¼Œæ¢¯åº¦éƒ½ä¼šç´¯åŠ ä¹‹å‰çš„æ¢¯åº¦ï¼Œæ‰€ä»¥åå‘ä¼ æ’­ä¹‹å‰éœ€æŠŠæ¢¯åº¦æ¸…é›¶ã€‚
~~~

### 11. optim -> form torch import optim

~~~python
import torch.optim as optim

optim.SGD(params, lr=0.01, momentum=0, dampening=0, weight_decay=0, nesterov=False)
optim.ASGD(params, lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)
optim.LBFGS(params, lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100, line_search_fn=None)
optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)
optim.Rprop(params, lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))
optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)
optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)
optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
optim.Adamax(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)
optim.SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)
optim.Optimizer(params, defaults)

optimizer.zero_grad()  # ç­‰ä»·äº net.zero_grad() 
optimizer.step()
~~~

### 12.  learning rate

~~~python
# Reduce learning rate when validation accuarcy plateau.
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)
# Cosine annealing learning rate.
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)
# Reduce learning rate by 10 at given epochs.
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)
# Learning rate warmup by 10 epochs.
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)

for t in range(0, 10):
    scheduler.step()
    train(...); val(...)
~~~

### 12. save and load model

~~~python
torch.save(model.state_dict(), 'xxxx_params.pth')
model.load_state_dict(t.load('xxxx_params.pth'))

torch.save(model, 'xxxx.pth')
model.torch.load('xxxx.pth')

all_data = dict(
    optimizer = optimizer.state_dict(),
    model = model.state_dict(),
    info = u'model and optim parameter'
)

t.save(all_data, 'xxx.pth')
all_data = t.load('xxx.pth')
all_data.keys()
~~~

### 13. torchvision

##### models

~~~python
from torchvision import models
resnet34 = models.resnet34(pretrained=True, num_classes=1000)
~~~

##### data augmentation  

~~~python
from torchvision import transforms

# transforms.CenterCrop           transforms.Grayscale           transforms.ColorJitter          
# transforms.Lambda               transforms.Compose             transforms.LinearTransformation 
# transforms.FiveCrop             transforms.Normalize           transforms.functional           
# transforms.Pad                  transforms.RandomAffine        transforms.RandomHorizontalFlip  
# transforms.RandomApply          transforms.RandomOrder         transforms.RandomChoice         
# transforms.RandomResizedCrop    transforms.RandomCrop          transforms.RandomRotation        
# transforms.RandomGrayscale      transforms.RandomSizedCrop     transforms.RandomVerticalFlip   
# transforms.ToTensor             transforms.Resize              transforms.transforms                                           
# transforms.TenCrop              transforms.Scale               transforms.ToPILImage
~~~

##### è‡ªå®šä¹‰ dataset

~~~python
from torch.utils.data import Dataset

class my_data(Dataset):
    def __init__(self, image_path, annotation_path, transform=None):
        # åˆå§‹åŒ–ï¼Œ è¯»å–æ•°æ®é›†
    def __len__(self):
        # è·å–æ•°æ®é›†çš„æ€»å¤§å°
    def __getitem__(self, id):
        # å¯¹äºåˆ¶å®šçš„ id, è¯»å–è¯¥æ•°æ®å¹¶è¿”å›    
~~~

**datasets**

~~~python
from torch.utils.data import Dataset, Dataloader
from torchvision.transforms as transforms

transform = transforms.Compose([
        transforms.ToTensor(), # convert to Tensor
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # normalization

dataset = ImageFolder(root, transform=transform, target_transform=None, loader=default_loader)
dataloader = DataLoader(dataset, 2, collate_fn=my_collate_fn, num_workers=1,shuffle=True)
for batch_datas, batch_labels in dataloader:
    ...
~~~

##### img process

~~~python
img = make_grid(next(dataiter)[0], 4) 
save_image(img, 'a.png')
~~~

##### data Visualization

~~~python
from torchvision.transforms import ToPILImage

show = ToPILImage()  # å¯ä»¥æŠŠTensorè½¬æˆImageï¼Œæ–¹ä¾¿å¯è§†åŒ–

(data, label) = trainset[100]
show((data + 1) / 2).resize((100, 100))  # åº”è¯¥ä¼šè‡ªåŠ¨ä¹˜ä»¥ 255 çš„
~~~

### 14. Code Samples

~~~python
# torch.device object used throughout this script
device = torch.device("cuda" if use_cuda else "cpu")

model = MyRNN().to(device)

# train
total_loss = 0
for input, target in train_loader:
    input, target = input.to(device), target.to(device)
    hidden = input.new_zeros(*h_shape)  # has the same device & dtype as `input`
    ...  # get loss and optimize
    total_loss += loss.item()           # get Python number from 1-element Tensor

# evaluate
with torch.no_grad():                   # operations inside don't track history
    for input, target in test_loader:
        ...
~~~

### 15. jit & torchscript

~~~python
from torch.jit import script, trace
torch.jit.trace(model, torch.rand(1,3,224,224)) ã€€# export model
@torch.jit.script
~~~

~~~cpp
#include <torch/torch.h>
#include <torch/script.h>

# img blob -> img tensor
torch::Tensor img_tensor = torch::from_blob(image.data, {1, image.rows, image.cols, 3}, torch::kByte);
img_tensor = img_tensor.permute({0, 3, 1, 2});
img_tensor = img_tensor.toType(torch::kFloat);
img_tensor = img_tensor.div(255);
# load model
std::shared_ptr<torch::jit::script::Module> module = torch::jit::load("resnet.pt");
# forward
torch::Tensor output = module->forward({img_tensor}).toTensor();
~~~

### 16. onnx

~~~python
torch.onnx.export(model, dummy data, xxxx.proto) # exports an ONNX formatted

model = onnx.load("alexnet.proto")               # load an ONNX model
onnx.checker.check_model(model)                  # check that the model

onnx.helper.printable_graph(model.graph)         # print a human readableã€€representation of the graph
~~~

### 17. Distributed Training

~~~python
import torch.distributed as dist          # distributed communication
from multiprocessing import Process       # memory sharing processes
~~~



## ä¸‰. How to Build a network

### åŸºæœ¬å·¥ä½œæµç¨‹

1. ç›¸å…³å·¥ä½œè°ƒç ”:  **è¯„ä»·æŒ‡æ ‡ã€æ•°æ®é›†ã€ç»å…¸è§£å†³æ–¹æ¡ˆã€å¾…è§£å†³é—®é¢˜å’Œå·²æœ‰æ–¹æ¡ˆçš„ä¸åŒã€ç²¾åº¦å’Œé€Ÿåº¦é¢„ä¼°ã€ç›¸å…³éš¾ç‚¹ ! **

2. æ•°æ®æ¢ç´¢å’Œæ–¹æ¡ˆç¡®å®š
3. ä¾æ¬¡ç¼–å†™æ¨¡å‹ models.pyã€æ•°æ®é›†è¯»å–æ¥å£ datasets.py ã€æŸå¤±å‡½æ•° losses.py ã€è¯„ä»·æŒ‡æ ‡ criterion.py
4. ç¼–å†™è®­ç»ƒè„šæœ¬(train.py)å’Œæµ‹è¯•è„šæœ¬(test.py)
5. è®­ç»ƒã€è°ƒè¯•å’Œæµ‹è¯„
6. æ¨¡å‹çš„éƒ¨ç½²

æ³¨æ„ï¼Œä¸è¦å°†æ‰€æœ‰å±‚å’Œæ¨¡å‹æ”¾åœ¨åŒä¸€ä¸ªæ–‡ä»¶ä¸­ã€‚æœ€ä½³åšæ³•æ˜¯å°†æœ€ç»ˆç½‘ç»œåˆ†ç¦»ä¸ºå•ç‹¬çš„æ–‡ä»¶ï¼ˆnetworks.pyï¼‰ï¼Œå¹¶å°†å±‚ã€æŸè€—å’Œ ops ä¿å­˜åœ¨å„è‡ªçš„æ–‡ä»¶ï¼ˆlayers.pyã€losses.pyã€ops.pyï¼‰ä¸­ã€‚å®Œæˆçš„æ¨¡å‹ï¼ˆç”±ä¸€ä¸ªæˆ–å¤šä¸ªç½‘ç»œç»„æˆï¼‰åº”åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­å¼•ç”¨ï¼Œæ–‡ä»¶åä¸º yolov3.pyã€dcgan.py è¿™æ ·ã€‚

##### (1) æ„å»ºç¥ç»ç½‘ç»œ

è‡ªå®šä¹‰çš„ç½‘ç»œç»§æ‰¿è‡ªä¸€èˆ¬ç»§æ‰¿è‡ªã€€nn.Module ç±»ï¼Œã€€å¿…é¡»æœ‰ä¸€ä¸ª forward æ–¹æ³•æ¥å®ç°å„ä¸ªå±‚æˆ–æ“ä½œçš„ forward ä¼ é€’ï¼Œã€€

å¯¹äºå…·æœ‰**å•ä¸ªè¾“å…¥**å’Œ**å•ä¸ªè¾“å‡º**çš„ç®€å•ç½‘ç»œï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ¨¡å¼ï¼š

~~~python
class ConvBlock(nn.Module):
  def __init__(self):
    super(ConvBlock, self).__init__()
    self.block = nn.Squential(
       nn.Conv2d(...),
       nn.ReLU(),
       nn.BatchNorm2d(...)
    )
   
  def forward(self, x):
    return self.block(x)

class SimpleNetwork(nn.Module):
    def __init__(self, num_of_layers = 15):
        super(SimpleNetwork, self).__init__()
        layers = list()
        for i in range(num_of_layers):
            layers.append(..)
        self.conv0 = nn.Sequential(*layers)

    def forward(self, x):
        out = self.conv0(x)
        return out
~~~

æˆ‘ä»¬å»ºè®®å°†ç½‘ç»œæ‹†åˆ†ä¸ºæ›´å°çš„**å¯é‡ç”¨éƒ¨åˆ†**ã€‚ç½‘ç»œç”±æ“ä½œæˆ–å…¶å®ƒç½‘ç»œæ¨¡å—ç»„æˆã€‚æŸå¤±å‡½æ•°ä¹Ÿæ˜¯ç¥ç»ç½‘ç»œçš„æ¨¡å—ï¼Œå› æ­¤å¯ä»¥ç›´æ¥é›†æˆåˆ°ç½‘ç»œä¸­ã€‚

##### (2) è‡ªå®šä¹‰æ•°æ®é›†

~~~python
class CustomDataset(Dataset):
    """ CustomDataset. """
    def __init__(self, root_dir='./data', transform=None):
        """
        """
        self.root_dir = root_dir
        self.transform = transform
        self.train_data = ...
        self.train_target = ...

    def __len__(self):
        return len(self.train_data)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        data = Image.open(self.train_data[idx])
        target = Image.open(self.train_target[idx])

        if self.transform:
            data, target = self.transform(data, target)

        sample = {'data': data, 'high_img': target}
        return sample
~~~

##### (3) è‡ªå®šä¹‰æŸå¤±

è™½ç„¶ PyTorch å·²ç»æœ‰å¾ˆå¤šæ ‡å‡†çš„æŸå¤±å‡½æ•°ï¼Œä½†æœ‰æ—¶ä¹Ÿå¯èƒ½éœ€è¦åˆ›å»ºè‡ªå·±çš„æŸå¤±å‡½æ•°ã€‚ä¸ºæ­¤ï¼Œè¯·åˆ›å»ºå•ç‹¬çš„æ–‡ä»¶ **losses.py** å¹¶æ‰©å±•**nn.module** ç±»ä»¥åˆ›å»ºè‡ªå®šä¹‰çš„æŸå¤±å‡½æ•°ï¼š

~~~python
import torch
import torch.nn as nn

class CustomLoss(nn.Module):
    def __init__(self):
        """ CustomLoss"""
        super(CustomLoss, self).__init__()

    def forward(self, x, y):
        return torch.mean(torch.square(x  - y))
~~~

##### (4) æ¨èä½¿ç”¨çš„ç”¨äºè®­ç»ƒæ¨¡å‹çš„ä»£ç ç»“æ„

~~~python
# import statements
import torch
import torch.nn as nn
from torch.utils import data
...

# set flags / seeds
torch.backends.cudnn.benchmark = True
np.random.seed(1)
torch.manual_seed(1)
torch.cuda.manual_seed(1)
...
  
# dataset
transform_train = ...
trainform_text = ...

train_dataset = CustomDataset(args.train_dataset, is_trainval = True, transform = transform_train) 
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size,
                                           shuffle=True, num_workers=0, drop_last=False) 
valid_dataset = CustomDataset(args.valid_dataset, is_trainval = True, transform = transform_test)  
valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.val_batch_size, 
                                           shuffle=True, num_workers=0) 
# model & loss
net = CustomNet().to(device) 
criterion = ...  
# lr & optimizer
optim = optim.SGD(model.parameters(), lr=args.init_lr, momentum=args.momentum, weight_decay=args.weight_decay)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)


# load resume
if args.resume:
    if os.path.isfile(args.resume):
        print("=> loading checkpoint '{}'".format(args.resume))
        checkpoint = torch.load(args.resume)
        args.start_epoch = checkpoint['epoch']
        best_prec = checkpoint['best_prec']
        model.load_state_dict(checkpoint['state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        print("=> loaded checkpoint '{}' (epoch {}) Prec: {:f}"
              .format(args.resume, checkpoint['epoch'], best_prec1))
    else:
        print("=> no checkpoint found at '{}'".format(args.resume))

def train(epoch):
    model.train()ã€€# åœ¨ã€€model(x)ã€€å‰éœ€è¦æ·»åŠ ã€€model.eval()ã€€æˆ–è€…ã€€model.eval()

    avg_loss = 0.0
    train_acc = 0.0
    for batch_idx, batchdata in enumerate(train_loader):
        data, target = batchdata["data"], batchdata["target"] #
        data, target = data.to(device), target.to(device)  #
        # åœ¨ loss.backward()ã€€å‰ç”¨ã€€optimizer.zero_grad()ã€€æ¸…é™¤ç´¯ç§¯æ¢¯åº¦
        optimizer.zero_grad() # optimizer.zero_gradã€€ä¸ã€€model.zero_gradæ•ˆæœä¸€æ ·

        predict = model(data) # 
        loss = criterion(predict, target) #
        avg_loss += loss.item() #

        loss.backward()
        optimizer.step()

        print('Train Epoch: {} [{}/{} ({:.1f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))

    if (epoch + 1) %  args.save_interval == 0:
        state = { 'epoch': epoch + 1,
                   'state_dict': model.state_dict(),
                   'best_prec': 0.0,
                   'optimizer': optimizer.state_dict()}
        model_path = os.path.join(args.checkpoint_dir, 'model_' + str(epoch) + '.pth')
        torch.save(state, model_path)


def test():
    model.eval()

    test_loss = 0
    for batch_idx, batchdata in enumerate(valid_loader):
        data, target = batchdata["data"], batchdata["target"] #
        data, target = data.to(device), target.to(device) #
        predict = model(data) # 
        test_loss += criterion(predict, target) #
        psnr = criterion(predict * 255, target * 255) #

    test_loss /= len(valid_loader.dataset)
    print('\nTest set: Average loss: {:.4f}, loss:{}, PSNR: ({:.1f})\n'.format(
        test_loss, test_loss / len(valid_loader.dataset), psnr / len(valid_loader.dataset)))
    return psnr / float(len(valid_loader.dataset))


best_prec = 0.0
for epoch in range(args.start_epoch, args.epochs):
    train(epoch)
    scheduler.step()
    print(print(optimizer.state_dict()['param_groups'][0]['lr']))

    current_prec = test() 
    is_best = current_prec > best_prec #ã€€æ›´æ”¹å¤§å°å†™ !
    best_prec = max(best_prec, best_prec) #  max or min

    save_checkpoint({
        'epoch': epoch + 1,
        'state_dict': model.state_dict(),
        'best_prec': best_prec,
        'optimizer': optimizer.state_dict(),
    }, is_best, args.checkpoint_dir)
~~~



## å››. å¸¸è§ä»£ç ç‰‡æ®µ

### 1. åŸºç¡€é…ç½®

##### (1) check pytorch version

~~~python
torch.__version__               # PyTorch version
torch.version.cuda              # Corresponding CUDA version
torch.backends.cudnn.version()  # Corresponding cuDNN version
torch.cuda.get_device_name(0)   # GPU type
~~~

##### (2) update pytorch

~~~
conda update pytorch torchvision -c pytorch
~~~

##### (3) random seed setting 

~~~
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
~~~

##### (4) æŒ‡å®šç¨‹åºè¿è¡Œåœ¨ç‰¹å®šæ˜¾å¡ä¸Šï¼š

åœ¨å‘½ä»¤è¡ŒæŒ‡å®šç¯å¢ƒå˜é‡

```
CUDA_VISIBLE_DEVICES=0,1 python train.py
```

åœ¨ä»£ç ä¸­æŒ‡å®š

~~~
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
~~~

##### (5) åˆ¤æ–­æ˜¯å¦æœ‰CUDAæ”¯æŒ

```
torch.cuda.is_available()
torch.set_default_tensor_type('torch.cuda.FloatTensor')   
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
```

##### (6) è®¾ç½®ä¸ºcuDNN benchmarkæ¨¡å¼

Benchmarkæ¨¡å¼ä¼šæå‡è®¡ç®—é€Ÿåº¦ï¼Œä½†æ˜¯ç”±äºè®¡ç®—ä¸­æœ‰éšæœºæ€§ï¼Œæ¯æ¬¡ç½‘ç»œå‰é¦ˆç»“æœç•¥æœ‰å·®å¼‚ã€‚

~~~
toch.backends.cudnn.benchmark = True
~~~

å¦‚æœæƒ³è¦é¿å…è¿™ç§ç»“æœæ³¢åŠ¨ï¼Œè®¾ç½®

~~~
torch.backends.cudnn.deterministic = True
~~~

##### (7) æ‰‹åŠ¨æ¸…é™¤GPUå­˜å‚¨

æœ‰æ—¶Control-Cä¸­æ­¢è¿è¡ŒåGPUå­˜å‚¨æ²¡æœ‰åŠæ—¶é‡Šæ”¾ï¼Œéœ€è¦æ‰‹åŠ¨æ¸…ç©ºã€‚åœ¨PyTorchå†…éƒ¨å¯ä»¥

~~~
torch.cuda.empty_cache() 
~~~

æˆ–åœ¨å‘½ä»¤è¡Œå¯ä»¥å…ˆä½¿ç”¨psæ‰¾åˆ°ç¨‹åºçš„PIDï¼Œå†ä½¿ç”¨killç»“æŸè¯¥è¿›ç¨‹

~~~
 ps aux | grep python    kill -9 [pid] 
~~~

æˆ–è€…ç›´æ¥é‡ç½®æ²¡æœ‰è¢«æ¸…ç©ºçš„GPU

~~~
nvidia-smi --gpu-reset -i [gpu_id]
~~~

### 2. æ¨¡å‹

##### (1) æå–ImageNeté¢„è®­ç»ƒæ¨¡å‹æŸå±‚çš„å·ç§¯ç‰¹å¾

~~~
# VGG-16 relu5-3 feature.
model = torchvision.models.vgg16(pretrained=True).features
# VGG-16 pool5 feature.
model = torchvision.models.vgg16(pretrained=True)
model = torch.nn.Sequential(model.features, model.avgpool)
# VGG-16 fc7 feature.
model = torchvision.models.vgg16(pretrained=True)
model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])
# ResNet GAP feature.
model = torchvision.models.resnet18(pretrained=True)
model = torch.nn.Sequential(collections.OrderedDict(
    list(model.named_children())[:-1]))

with torch.no_grad():
    model.eval()
    conv_representation = model(image)
~~~

##### (2) æå–ImageNeté¢„è®­ç»ƒæ¨¡å‹å¤šå±‚çš„å·ç§¯ç‰¹å¾

~~~
class FeatureExtractor(torch.nn.Module):
    """Helper class to extract several convolution features from the given
    pre-trained model.

    Attributes:
        _model, torch.nn.Module.
        _layers_to_extract, list<str> or set<str>

    Example:
        >>> model = torchvision.models.resnet152(pretrained=True)
        >>> model = torch.nn.Sequential(collections.OrderedDict(
                list(model.named_children())[:-1]))
        >>> conv_representation = FeatureExtractor(
                pretrained_model=model,
                layers_to_extract={'layer1', 'layer2', 'layer3', 'layer4'})(image)
    """
    def __init__(self, pretrained_model, layers_to_extract):
        torch.nn.Module.__init__(self)
        self._model = pretrained_model
        self._model.eval()
        self._layers_to_extract = set(layers_to_extract)
    
    def forward(self, x):
        with torch.no_grad():
            conv_representation = []
            for name, layer in self._model.named_children():
                x = layer(x)
                if name in self._layers_to_extract:
                    conv_representation.append(x)
            return conv_representation
~~~

##### (ï¼“)  éƒ¨åˆ†å±‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹

æ³¨æ„å¦‚æœä¿å­˜çš„æ¨¡å‹æ˜¯`torch.nn.DataParallel`ï¼Œåˆ™å½“å‰çš„æ¨¡å‹ä¹Ÿéœ€è¦æ˜¯`torch.nn.DataParallel`ã€‚`torch.nn.DataParallel(model).module == model`ã€‚

~~~
   model.load_state_dict(torch.load('model,pth'), strict=False)
~~~

å°†åœ¨GPUä¿å­˜çš„æ¨¡å‹åŠ è½½åˆ°CPU:

~~~
   model.load_state_dict(torch.load('model,pth', map_location='cpu'))
~~~

##### ï¼ˆï¼”ï¼‰fine-tune å¾®è°ƒå…¨è¿æ¥å±‚

##### (4) å¾®è°ƒå…¨è¿æ¥å±‚

~~~
model = torchvision.models.resnet18(pretrained=True)
for param in model.parameters():
    param.requires_grad = False
model.fc = nn.Linear(512, 100)  # Replace the last fc layer
optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)
~~~

ä»¥è¾ƒå¤§å­¦ä¹ ç‡å¾®è°ƒå…¨è¿æ¥å±‚ï¼Œè¾ƒå°å­¦ä¹ ç‡å¾®è°ƒå·ç§¯å±‚

~~~
model = torchvision.models.resnet18(pretrained=True)
finetuned_parameters = list(map(id, model.fc.parameters()))
conv_parameters = (p for p in model.parameters() if id(p) not in finetuned_parameters)
parameters = [{'parameters': conv_parameters, 'lr': 1e-3}, 
              {'parameters': model.fc.parameters()}]
optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)
~~~

##### ï¼ˆï¼•ï¼‰ä¿å­˜ä¸åŠ è½½æ–­ç‚¹

æ³¨æ„ä¸ºäº†èƒ½å¤Ÿæ¢å¤è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦åŒæ—¶ä¿å­˜æ¨¡å‹å’Œä¼˜åŒ–å™¨çš„çŠ¶æ€ï¼Œä»¥åŠå½“å‰çš„è®­ç»ƒè½®æ•°ã€‚

~~~
# Save checkpoint.
is_best = current_acc > best_acc
best_acc = max(best_acc, current_acc)
checkpoint = {
    'best_acc': best_acc,    
    'epoch': t + 1,
    'model': model.state_dict(),
    'optimizer': optimizer.state_dict(),
}
model_path = os.path.join('model', 'checkpoint.pth.tar')
torch.save(checkpoint, model_path)
if is_best:
    shutil.copy('checkpoint.pth.tar', model_path)

# Load checkpoint.
if resume:
    model_path = os.path.join('model', 'checkpoint.pth.tar')
    assert os.path.isfile(model_path)
    checkpoint = torch.load(model_path)
    best_acc = checkpoint['best_acc']
    start_epoch = checkpoint['epoch']
    model.load_state_dict(checkpoint['model'])
    optimizer.load_state_dict(checkpoint['optimizer'])
    print('Load checkpoint at epoch %d.' % start_epoch)
~~~

##### (ï¼–) è®¡ç®—æ¨¡å‹å‚æ•°é‡[D]

~~~
# Total parameters                    
num_params = sum(p.numel() for p in model.parameters()) 
# Trainable parameters
num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)  
~~~

##### (ï¼—) æ¨¡å‹æƒå€¼åˆå§‹åŒ–[D]

æ³¨æ„`model.modules()`å’Œ`model.children()`çš„åŒºåˆ«ï¼š`model.modules()`ä¼šè¿­ä»£åœ°éå†æ¨¡å‹çš„æ‰€æœ‰å­å±‚ï¼Œè€Œ`model.children()`åªä¼šéå†æ¨¡å‹ä¸‹çš„ä¸€å±‚ã€‚

~~~python
# Common practise for initialization.
for m in model.modules():
    if isinstance(m, torch.nn.Conv2d):
        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out',
                                      nonlinearity='relu')
        if m.bias is not None:
            torch.nn.init.constant_(m.bias, val=0.0)
    
    elif isinstance(m, torch.nn.BatchNorm2d):
        torch.nn.init.constant_(m.weight, 1.0)
        torch.nn.init.constant_(m.bias, 0.0)
  
    elif isinstance(m, torch.nn.Linear):
        torch.nn.init.xavier_normal_(m.weight)
        if m.bias is not None:
            torch.nn.init.constant_(m.bias, 0.0)

# Initialization with given tensor.
m.weight = torch.nn.Parameter(tensor)
~~~

##### (8) å†»ç»“å‚æ•°

~~~
if not requires_grad:
    for param in self.parameters():
        param.requires_grad = False
~~~

### 3. æ•°æ®

##### (1) å¸¸è§è®­ç»ƒå’ŒéªŒè¯æ•°æ®é¢„å¤„ç†

ToTensoræ“ä½œä¼šå°†PIL.Imageæˆ–å½¢çŠ¶ä¸ºHÃ—WÃ—Dï¼Œæ•°å€¼èŒƒå›´ä¸º[0, 255]çš„np.ndarrayè½¬æ¢ä¸ºå½¢çŠ¶ä¸ºDÃ—HÃ—Wï¼Œæ•°å€¼èŒƒå›´ä¸º[0.0, 1.0]çš„torch.Tensorã€‚

~~~
train_transform = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(size=224,
                                             scale=(0.08, 1.0)),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),
                                     std=(0.229, 0.224, 0.225)),
 ])
 val_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize(224),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),
                                     std=(0.229, 0.224, 0.225)),
])
~~~

### 4. è®­ç»ƒ

##### (1) å°†æ•´æ•°æ ‡è®°è½¬æ¢æˆç‹¬çƒ­ï¼ˆone-hotï¼‰ç¼–ç   

 (PyTorchä¸­çš„æ ‡è®°é»˜è®¤ä»0å¼€å§‹)

~~~
   N = tensor.size(0)
   one_hot = torch.zeros(N, num_classes).long()
   one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())
~~~

##### (2) è®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„ä¸¤ä¸¤æ¬§å¼è·ç¦»

~~~
# X1 is of shape m*d.
X1 = torch.unsqueeze(X1, dim=1).expand(m, n, d)
# X2 is of shape n*d.
X2 = torch.unsqueeze(X2, dim=0).expand(m, n, d)
# dist is of shape m*n, where dist[i][j] = sqrt(|X1[i, :] - X[j, :]|^2)
dist = torch.sqrt(torch.sum((X1 - X2) ** 2, dim=2))
~~~

##### (3) åŒçº¿æ€§æ±‡åˆï¼ˆbilinear poolingï¼‰

~~~
X = torch.reshape(N, D, H * W)                        # Assume X has shape N*D*H*W
X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  # Bilinear pooling
assert X.size() == (N, D, D)
X = torch.reshape(X, (N, D * D))
X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)   # Signed-sqrt normalization
X = torch.nn.functional.normalize(X)                  # L2 normalization
~~~

##### (4) L1 æ­£åˆ™åŒ–

~~~
l1_regularization = torch.nn.L1Loss(reduction='sum')
loss = ...  # Standard cross-entropy loss
for param in model.parameters():
    loss += torch.sum(torch.abs(param))
loss.backward()


reg = 1e-6
l2_loss = Variable(torch.FloatTensor(1), requires_grad=True)
for name, param in model.named_parameters():
    if 'bias' not in name:
        l2_loss = l2_loss + (0.5 * reg * torch.sum(torch.pow(W, 2)))
~~~

##### (5) ä¸å¯¹åç½®é¡¹è¿›è¡ŒL2æ­£åˆ™åŒ–/æƒå€¼è¡°å‡ï¼ˆweight decayï¼‰

~~~
bias_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias')
others_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias')
parameters = [{'parameters': bias_list, 'weight_decay': 0},                
              {'parameters': others_list}]
optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)
~~~

##### (6) æ¢¯åº¦è£å‰ªï¼ˆgradient clippingï¼‰

 ~~~
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)
 ~~~

##### (7) è®¡ç®—Softmax è¾“å‡ºçš„æ­£ç¡®ç‡

~~~
score = model(images)
prediction = torch.argmax(score, dim=1)
num_correct = torch.sum(prediction == labels).item()
accuruacy = num_correct / labels.size(0)
~~~

##### (8) è·å–å½“å‰å­¦ä¹ ç‡

~~~
# If there is one global learning rate (which is the common case).
lr = next(iter(optimizer.param_groups))['lr']
# If there are multiple learning rates for different layers.
all_lr = []
for param_group in optimizer.param_groups:
    all_lr.append(param_group['lr'])
~~~

### 5. Trick

##### (1)  label smothing

~~~
for images, labels in train_loader:
    images, labels = images.cuda(), labels.cuda()
    N = labels.size(0)
    # C is the number of classes.
    smoothed_labels = torch.full(size=(N, C), fill_value=0.1 / (C - 1)).cuda()
    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=0.9)

    score = model(images)
    log_prob = torch.nn.functional.log_softmax(score, dim=1)
    loss = -torch.sum(log_prob * smoothed_labels) / N
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
~~~

##### (2) Mixup

~~~
beta_distribution = torch.distributions.beta.Beta(alpha, alpha)
for images, labels in train_loader:
    images, labels = images.cuda(), labels.cuda()

    # Mixup images.
    lambda_ = beta_distribution.sample([]).item()
    index = torch.randperm(images.size(0)).cuda()
    mixed_images = lambda_ * images + (1 - lambda_) * images[index, :]

    # Mixup loss.    
    scores = model(mixed_images)
    loss = (lambda_ * loss_function(scores, labels) 
            + (1 - lambda_) * loss_function(scores, labels[index]))

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
~~~

##### (3) å¤šå¡åŒæ­¥BNï¼ˆBatch normalizationï¼‰

å½“ä½¿ç”¨torch.nn.DataParallelå°†ä»£ç è¿è¡Œåœ¨å¤šå¼ GPUå¡ä¸Šæ—¶ï¼ŒPyTorchçš„BNå±‚é»˜è®¤æ“ä½œæ˜¯å„å¡ä¸Šæ•°æ®ç‹¬ç«‹åœ°è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ŒåŒæ­¥BNä½¿ç”¨æ‰€æœ‰å¡ä¸Šçš„æ•°æ®ä¸€èµ·è®¡ç®—BNå±‚çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œç¼“è§£äº†å½“æ‰¹é‡å¤§å°ï¼ˆbatch sizeï¼‰æ¯”è¾ƒå°æ—¶å¯¹å‡å€¼å’Œæ ‡å‡†å·®ä¼°è®¡ä¸å‡†çš„æƒ…å†µï¼Œæ˜¯åœ¨ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ä¸­ä¸€ä¸ªæœ‰æ•ˆçš„æå‡æ€§èƒ½çš„æŠ€å·§ã€‚

å‚è§ï¼š [Synchronized-BatchNorm-PyTorchgithub](vacancy/Synchronized-BatchNorm-PyTorchgithub.com)



## äº”. ç½‘ç»œä¼˜åŒ–å’ŒåŠ é€Ÿ [alpha]

### 1. æ•°æ®

##### (0) dataloader

- num_workersä¸batch_sizeè°ƒåˆ°åˆé€‚å€¼ï¼Œå¹¶éè¶Šå¤§è¶Šå¿«ï¼ˆæ³¨æ„åè€…ä¹Ÿå½±å“æ¨¡å‹æ€§èƒ½ï¼‰(éœ€è¦åœ¨å®éªŒä¸­æ‰¾åˆ°æœ€å¿«çš„å–å€¼)
- eval/testæ—¶shuffle=False
- å†…å­˜å¤Ÿå¤§çš„æƒ…å†µä¸‹ï¼Œdataloaderçš„**pin_memory**è®¾ä¸ºTrueã€‚å¯¹ç‰¹åˆ«å°çš„æ•°æ®é›†å¦‚ MNIST è®¾ç½® `pin_memory=False`  åè€Œæ›´å¿«ä¸€äº›ã€‚

#####  (1) é¢„å¤„ç†æé€Ÿ

- å°½é‡å‡å°‘æ¯æ¬¡è¯»å–æ•°æ®æ—¶çš„é¢„å¤„ç†æ“ä½œï¼Œå¯ä»¥è€ƒè™‘æŠŠä¸€äº›å›ºå®šçš„æ“ä½œï¼Œä¾‹å¦‚ resize ï¼Œäº‹å…ˆå¤„ç†å¥½ä¿å­˜ä¸‹æ¥ï¼Œè®­ç»ƒçš„æ—¶å€™ç›´æ¥æ‹¿æ¥ç”¨
- Linuxä¸Šå°†é¢„å¤„ç†æ¬åˆ°GPUä¸ŠåŠ é€Ÿï¼š

- - **NVIDIA/DALI** ï¼šhttps://github.com/NVIDIA/DALI
  - https://github.com/tanglang96/DataLoaders_DALI

- æ•°æ®é¢„å–ï¼šprefetch_generatorï¼ˆ[æ–¹æ³•](https://zhuanlan.zhihu.com/p/80695364)ï¼‰è®©è¯»æ•°æ®çš„workerèƒ½åœ¨è¿ç®—æ—¶é¢„è¯»æ•°æ®ï¼Œè€Œé»˜è®¤æ˜¯æ•°æ®æ¸…ç©ºæ—¶æ‰è¯»

##### (2) IO æé€Ÿ

- ä½¿ç”¨æ›´å¿«çš„å›¾ç‰‡å¤„ç†ï¼š

- - **opencv ä¸€èˆ¬è¦æ¯” PIL è¦å¿«**
  - å¯¹äºjpegè¯»å–ï¼Œå¯ä»¥å°è¯• **jpeg4py**
  - å­˜ **bmp** å›¾ï¼ˆé™ä½è§£ç æ—¶é—´ï¼‰

- **å°å›¾æ‹¼èµ·æ¥å­˜æ”¾ï¼ˆé™ä½è¯»å–æ¬¡æ•°ï¼‰ï¼šå¯¹äºå¤§è§„æ¨¡çš„å°æ–‡ä»¶è¯»å–ï¼Œå»ºè®®è½¬æˆå•ç‹¬çš„æ–‡ä»¶ï¼Œå¯ä»¥é€‰æ‹©çš„æ ¼å¼å¯ä»¥è€ƒè™‘**ï¼šTFRecordï¼ˆTensorflowï¼‰ã€recordIO(recordIO)ã€hdf5ã€ pthã€n5ã€lmdb ç­‰ç­‰ï¼ˆhttps://github.com/Lyken17/Efficient-PyTorch#data-loaderï¼‰

- - **TFRecord**ï¼šhttps://github.com/vahidk/tfrecord
  - å€ŸåŠ© **lmdb æ•°æ®åº“æ ¼å¼**ï¼š

- - - https://github.com/Fangyh09/Image2LMDB
    - https://blog.csdn.net/P_LarT/article/details/103208405
    - https://github.com/lartpang/PySODToolBox/blob/master/ForBigDataset/ImageFolder2LMDB.py
    - https://github.com/Lyken17/Efficient-PyTorch

##### (3)ã€€å€ŸåŠ©ç¡¬ä»¶

- å€ŸåŠ©å†…å­˜ï¼š**ç›´æ¥è½½åˆ°å†…å­˜é‡Œé¢ï¼Œæˆ–è€…æŠŠæŠŠå†…å­˜æ˜ å°„æˆç£ç›˜å¥½äº†**
- å€ŸåŠ©å›ºæ€ï¼šæŠŠè¯»å–é€Ÿåº¦æ…¢çš„æœºæ¢°ç¡¬ç›˜æ¢æˆ **NVME å›ºæ€**å§ï½

##### (4) è®­ç»ƒç­–ç•¥

- åœ¨è®­ç»ƒä¸­ä½¿ç”¨**ä½ç²¾åº¦ï¼ˆFP16 ç”šè‡³ INT8 ã€äºŒå€¼ç½‘ç»œã€ä¸‰å€¼ç½‘ç»œï¼‰è¡¨ç¤ºå–ä»£åŸæœ‰ç²¾åº¦ï¼ˆFP32ï¼‰è¡¨ç¤º**

- - NVIDIA/Apexï¼š

- - - https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/100135729
    - https://github.com/nvidia/apex

- ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒã€€DDP æˆ–è€… horovod

##### (5) ä»£ç å±‚é¢

- `torch.backends.cudnn.benchmark = True`
- Do numpy-like operations on the GPU wherever you can
- Free up memory using` del`     ç”¨`del`åŠæ—¶åˆ é™¤ä¸ç”¨çš„ä¸­é—´å˜é‡ï¼ŒèŠ‚çº¦GPUå­˜å‚¨ã€‚
- Avoid unnecessary transfer of data from the GPU
- Use pinned memory, and use non_blocking=False to parallelize data transfer and GPU number crunching

### 2. model

1. ç”¨**float16**ä»£æ›¿é»˜è®¤çš„float32è¿ç®—ï¼ˆ[æ–¹æ³•å‚è€ƒ](https://link.zhihu.com/?target=https%3A//github.com/huggingface/transformers/blob/dad3c7a485b7ffc6fd2766f349e6ee845ecc2eee/examples/run_classifier.py)ï¼Œæœç´¢"fp16"å¯ä»¥çœ‹åˆ°éœ€è¦ä¿®æ”¹ä¹‹å¤„ï¼ŒåŒ…æ‹¬modelã€optimizerã€backwardã€learning rateï¼‰

2. **ä¼˜åŒ–å™¨**ä»¥åŠå¯¹åº”å‚æ•°çš„é€‰æ‹©ï¼Œå¦‚learning rateï¼Œä¸è¿‡å®ƒå¯¹æ€§èƒ½çš„å½±å“ä¼¼ä¹æ›´é‡è¦ã€å å‘ã€‘

3. å°‘ç”¨å¾ªç¯ï¼Œå¤šç”¨**å‘é‡åŒ–**æ“ä½œ

4. ç»å…¸æ“ä½œå°½é‡ç”¨åˆ«äººä¼˜åŒ–å¥½çš„**åº“**ï¼Œåˆ«è‡ªå·±å†™

5. æ•°æ®å¾ˆå¤šæ—¶å°‘ç”¨appendï¼Œè™½ç„¶ä½¿ç”¨å¾ˆæ–¹ä¾¿ï¼Œä¸è¿‡å®ƒæ¯æ¬¡éƒ½ä¼šé‡æ–°åˆ†é…ç©ºé—´ï¼Ÿæ‰€ä»¥æ•°æ®å¾ˆå¤§çš„è¯ï¼Œå…‰ä¸€æ¬¡appendå°±è¦å‡ ç§’ï¼ˆæµ‹è¿‡ï¼‰ï¼Œå¯ä»¥å…ˆåˆ†é…å¥½æ•´ä¸ªå®¹å™¨å¤§å°ï¼Œæ¯æ¬¡ç”¨ç´¢å¼•å»ä¿®æ”¹å†…å®¹ï¼Œè¿™æ ·ä¸€æ­¥åªè¦0.0xç§’

6. å›ºå®šå¯¹æ¨¡å‹å½±å“ä¸å¤§çš„éƒ¨åˆ†å‚æ•°ï¼Œè¿˜èƒ½èŠ‚çº¦æ˜¾å­˜ï¼Œå¯ä»¥ç”¨ detach() åˆ‡æ–­åå‘ä¼ æ’­ï¼Œæ³¨æ„è‹¥ä»…ä»…ç»™å˜é‡è®¾ç½® required_grad=False è¿˜æ˜¯ä¼šè®¡ç®—æ¢¯åº¦çš„

7. eval/test çš„æ—¶å€™ï¼ŒåŠ ä¸Š model.eval() å’Œ torch.no_grad()ï¼Œå‰è€…å›ºå®š batch-normalization å’Œ dropout ä½†æ˜¯ä¼šå½±å“æ€§èƒ½ï¼Œåè€…å…³é—­ autograd

8. æé«˜ç¨‹åº**å¹¶è¡Œåº¦**ï¼Œä¾‹å¦‚ æˆ‘æƒ³ train æ—¶å¯¹æ¯ä¸ª epoch éƒ½èƒ½ test ä¸€ä¸‹ä»¥è¿½è¸ªæ¨¡å‹æ€§èƒ½å˜åŒ–ï¼Œä½†æ˜¯ test æ—¶é—´æˆæœ¬å¤ªé«˜è¦ä¸€ä¸ªå°æ—¶ï¼Œæ‰€ä»¥å†™äº†ä¸ª socketï¼Œè®¾ä¸€ä¸ª127.0.0.1 çš„ç«¯å£ï¼Œæ¯æ¬¡ train å®Œä¸€ä¸ª epoch å°±å‘ä¸ªUDPè¿‡å»ï¼Œé‚£ä¸ªè¿›ç¨‹å°±å¯ä»¥è‡ªå·± testï¼ŒåŒæ—¶åŸè¿›ç¨‹å¯ä»¥ç»§ç»­ train ä¸‹ä¸€ä¸ª epochï¼ˆå¯¹ è¿™æ˜¯è‡ªå·±æƒ³çš„è¯¡å¼‚æ–¹æ³•hhhï¼‰

9. torch.backends.cudnn.benchmarkè®¾ä¸ºTrueï¼Œå¯ä»¥è®©cudnnæ ¹æ®å½“å‰è®­ç»ƒå„é¡¹configå¯»æ‰¾ä¼˜åŒ–ç®—æ³•ï¼Œä½†è¿™æœ¬èº«éœ€è¦æ—¶é—´ï¼Œæ‰€ä»¥input sizeåœ¨è®­ç»ƒæ—¶ä¼šé¢‘ç¹å˜åŒ–çš„è¯ï¼Œå»ºè®®è®¾ä¸ºFalse

10. ä½¿ç”¨`inplace`æ“ä½œå¯èŠ‚çº¦ GPU å­˜å‚¨ï¼Œå¦‚

    ~~~
    x = torch.nn.functional.relu(x, inplace=True)
    ~~~

11. å‡å°‘CPUå’ŒGPUä¹‹é—´çš„æ•°æ®ä¼ è¾“ã€‚ä¾‹å¦‚ï¼Œ å¦‚æœä½ æƒ³çŸ¥é“ä¸€ä¸ª epoch ä¸­æ¯ä¸ª mini-batch çš„ loss å’Œå‡†ç¡®ç‡ï¼Œå…ˆå°†å®ƒä»¬ç´¯ç§¯åœ¨ GPU ä¸­ç­‰ä¸€ä¸ª epoch ç»“æŸä¹‹åä¸€èµ·ä¼ è¾“å› CPU ä¼šæ¯”æ¯ä¸ª mini-batch éƒ½è¿›è¡Œä¸€æ¬¡ GPU åˆ° CPU çš„ä¼ è¾“æ›´å¿«ã€‚

12. ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°`half()`ä¼šæœ‰ä¸€å®šçš„é€Ÿåº¦æå‡ï¼Œå…·ä½“æ•ˆç‡ä¾èµ–äºGPUå‹å·ã€‚éœ€è¦å°å¿ƒæ•°å€¼ç²¾åº¦è¿‡ä½å¸¦æ¥çš„ç¨³å®šæ€§é—®é¢˜ã€‚æ—¶å¸¸ä½¿ç”¨ `assert tensor.size() == (N, D, H, W)`ä½œä¸ºè°ƒè¯•æ‰‹æ®µï¼Œç¡®ä¿å¼ é‡ç»´åº¦å’Œä½ è®¾æƒ³ä¸­ä¸€è‡´ã€‚

13. é™¤äº†æ ‡è®° y å¤–ï¼Œå°½é‡å°‘ä½¿ç”¨ä¸€ç»´å¼ é‡ï¼Œä½¿ç”¨n*1çš„äºŒç»´å¼ é‡ä»£æ›¿ï¼Œå¯ä»¥é¿å…ä¸€äº›æ„æƒ³ä¸åˆ°çš„ä¸€ç»´å¼ é‡è®¡ç®—ç»“æœã€‚

14.  ç»Ÿè®¡ä»£ç å„éƒ¨åˆ†è€—æ—¶

~~~python
with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:
    ...
    print(profile)
~~~

æˆ–è€…åœ¨å‘½ä»¤è¡Œè¿è¡Œï¼š

~~~
python -m torch.utils.bottleneck main.py
~~~



## å…­. åˆ†å¸ƒå¼è®­ç»ƒ [alpha]

~~~
os.environ['NCCL_SOCKET_IFNAME'] = 'enp2s0'
os.environ['GLOO_SOCKET_IFNAME'] = 'enp2s0'
~~~

#### nn.DataParallel

~~~
gpus = [0, 1, 2, 3]
torch.cuda.set_device('cuda:{}'.format(gpus[0]))

model = nn.DataParallel(model.to(device), device_ids=gpus, output_device=gpus[0])
~~~

#### torch.distributed

~~~
parser = argparse.ArgumentParser()
parser.add_argument('--backend', type=str, default='nccl', help='Name of the backend to use.')
parser.add_argument('-i',
                    '--init-method',
                    type=str,
                    default='env://',
                    help='URL specifying how to initialize the package.')
parser.add_argument('-ws', '--world-size', type=int, default=1, help='Number of processes participating in the job.')
parser.add_argument('-r', '--rank', type=int, default=0, help='Rank of the current process.')
args = parser.parse_args()
~~~

~~~
distributed.init_process_group(
    backend=args.backend,
    init_method=args.init_method,
    world_size=args.world_size,
    rank=args.rank,
)
~~~

~~~
train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=..., sampler=train_sampler)
~~~

~~~
model = nn.parallel.DistributedDataParallel(model)
~~~

####ã€€torch.multiprocessing

~~~
import torch.multiprocessing as mp
mp.spawn(main_worker, nprocs=4, args=(4, myargs))
~~~

#### APEX

~~~
from apex import amp
from apex.parallel import DistributedDataParallel
~~~

~~~
model, optimizer = amp.initialize(model, optimizer)
model = DistributedDataParallel(model)

with amp.scale_loss(loss, optimizer) as scaled_loss:
   scaled_loss.backward()
~~~

#### Horovod

```
import horovod.torch as hvd

hvd.local_rank()
```

~~~
hvd.init()
~~~

~~~
train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=..., sampler=train_sampler)
~~~

~~~
hvd.broadcast_parameters(model.state_dict(), root_rank=0)
~~~

~~~
hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters(), compression=hvd.Compression.fp16)
~~~



## ä¸ƒ. ç§»åŠ¨ç«¯éƒ¨ç½²

- æ¨¡å‹å‹ç¼©å’ŒåŠ é€Ÿ(é‡åŒ–ã€å‰ªæ)
- Pytorch to onnx to X



## å…«. æœåŠ¡å™¨ç«¯éƒ¨ç½² 

- flask_api
- TensorRT



## ä¹. æœ€ä½³å®è·µ(To do or not to do)

**åœ¨ã€Œnn.Moduleã€çš„ã€Œforwardã€æ–¹æ³•ä¸­é¿å…ä½¿ç”¨ Numpy ä»£ç **

Numpy æ˜¯åœ¨ CPU ä¸Šè¿è¡Œçš„ï¼Œå®ƒæ¯” torch çš„ä»£ç è¿è¡Œå¾—è¦æ…¢ä¸€äº›ã€‚ç”±äº torch çš„å¼€å‘æ€è·¯ä¸ numpy ç›¸ä¼¼ï¼Œæ‰€ä»¥å¤§å¤šæ•°  ä¸­çš„å‡½æ•°å·²ç»åœ¨ PyTorch ä¸­å¾—åˆ°äº†æ”¯æŒã€‚



## å. ToolBox [alpha]

### 1. é¢„è®­ç»ƒæ¨¡å‹

https://github.com/Cadene/pretrained-models.pytorch

https://github.com/rwightman/pytorch-image-models

https://github.com/welkin-feng/ComputerVision

### 2. æ•°æ®å¢å¼º

https://github.com/albumentations-team/albumentations

### 3. æ ‡è®°å·¥å…·

[**Labelme:**](https://github.com/wkentaro/labelme) Image Polygonal Annotation with Python

[**LabelImg**](https://github.com/tzutalin/labelImg)ï¼šLabelImg is a graphical image annotation tool and label object bounding boxes in images

### 4. æ•°æ®é›†æŸ¥æ‰¾

è®ºæ–‡çš„è¯„æµ‹æŒ‡æ ‡ã€€=> datasets

[**Kaggle**](https://www.kaggle.com/)

[**Google Datasets Search Engine**](https://toolbox.google.com/datasetsearch)

[**Microsoft Datasets**](https://msropendata.com/)

[**Computer Vision Datasets**](https://www.visualdata.io/)

[**Github awesomedata**](https://github.com/awesomedata/awesome-public-datasets)

[**UCI Machine Learning Repository.**](https://archive.ics.uci.edu/ml/datasets.html)

[**Amazon Datasets**](https://registry.opendata.aws/)

**Government Datasets:** [**EU**](https://data.europa.eu/euodp/data/dataset) [**US**](https://www.data.gov/) [**NZL**](https://catalogue.data.govt.nz/dataset) [**IND**](https://data.gov.in/)

### 5. æ¨¡å‹åˆ†æå·¥å…·

##### (1) å·ç§¯å±‚è¾“å‡ºå¤§å°è®¡ç®—

##### https://ezyang.github.io/convolution-visualizer/index.html

##### (2) è®¡ç®—æ¨¡å‹å‚æ•°é‡

https://github.com/sksq96/pytorch-summary

##### (3) æ¨¡å‹å¯è§†åŒ–å·¥å…·

[**Netron:**](https://github.com/lutzroeder/Netron) now supports **ONNX**, **Keras**, **CoreML**, **Caffe2**, **Mxnet**, **Pytorch** and **Tensorflow**.

[**Graphviz:**](https://github.com/szagoruyko/pytorchviz) **Pytorch**

### 6. å¯è§†åŒ–å·¥å…·

[visdom](https://github.com/facebookresearch/visdom)

~~~python
# Example using Visdom.
vis = visdom.Visdom(env='Learning curve', use_incoming_socket=False)
assert self._visdom.check_connection()
self._visdom.close()
options = collections.namedtuple('Options', ['loss', 'acc', 'lr'])(
    loss={'xlabel': 'Epoch', 'ylabel': 'Loss', 'showlegend': True},
    acc={'xlabel': 'Epoch', 'ylabel': 'Accuracy', 'showlegend': True},
    lr={'xlabel': 'Epoch', 'ylabel': 'Learning rate', 'showlegend': True})

for t in epoch(80):
    tran(...)
    val(...)
    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([train_loss]),
             name='train', win='Loss', update='append', opts=options.loss)
    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([val_loss]),
             name='val', win='Loss', update='append', opts=options.loss)
    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([train_acc]),
             name='train', win='Accuracy', update='append', opts=options.acc)
    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([val_acc]),
             name='val', win='Accuracy', update='append', opts=options.acc)
    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([lr]),
             win='Learning rate', update='append', opts=options.lr)
~~~

[Tensorboard](https://pytorch.org/docs/stable/tensorboard.html)

- **acc / loss**

```python
from tensorboardX import SummaryWriter
writer = SummaryWriter()
for n_iter in range(100):
    dummy_s1 = torch.rand(1)
    writer.add_scalar('data/scalar1', dummy_s1[0], n_iter)
writer.close()
```

- **img**

```python
from tensorboardX import SummaryWriter
import torchvision.utils as vutils
writer = SummaryWriter()
if n_iter % 10 == 0:
    x = vutils.make_grid(dummy_img, normalize=True, scale_each=True)
    writer.add_image('Image', x, n_iter)
writer.close()
```

- åœ¨ä¸€å¼ å›¾ä¸­åŠ å…¥ä¸¤æ¡æ›²çº¿

```python
for i in range(100):
    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),
                                    'xcosx':i*np.cos(i/r),
                                    'tanx': np.tan(i/r)}, i)
```

### 7. Pytorch åŠ é€Ÿ

**NVIDIA/DLAI:** https://github.com/NVIDIA/DALI

**Efficient-Pytorch:** https://github.com/Lyken17/Efficient-PyTorch

**NVIDIA/APEX:** https://github.com/nvidia/apex

### 8. æ€§èƒ½åˆ†æå·¥å…·

- nvidia-smi
- htop
- iotop
- nvtop
- py-spy
- strace



## å‚è€ƒé“¾æ¥ [alpha]

- Tensorflow cookbook

- https://github.com/kevinzakka/pytorch-goodies

- https://github.com/chenyuntc/pytorch-book

- pytorch å®˜æ–¹æ–‡æ¡£å’Œtutorial

- https://github.com/IgorSusmelj/pytorch-styleguide


